model_config:
  image_size: 64
  num_channels: 384
  num_res_blocks: 3
  channel_mult: ''
  num_heads: 1
  num_head_channels: 64
  num_heads_upsample: -1
  attention_resolutions: 32,16,8
  dropout: 0
  model_dim: 768
  use_scale_shift_norm: true
  resblock_updown: true
  use_fp16: true
  cache_text_emb: true
  text_encoder_in_dim1: 1024
  text_encoder_in_dim2: 640
  pooling_type: from_model
  in_channels: 4
  out_channels: 8
  up: false
  inpainting: false

diffusion_config:
  learn_sigma: true
  sigma_small: false
  steps: 1000
  noise_schedule: linear
  timestep_respacing: ''
  use_kl: false
  predict_xstart: false
  rescale_timesteps: true
  rescale_learned_sigmas: true

image_enc_params:
  name: AutoencoderKL
  scale: 0.0512
    
  params:
    ckpt_path: /home/jovyan/cene655/model.ckpt
    embed_dim: 4
    ddconfig:
      double_z: true
      z_channels: 4
      resolution: 256
      in_channels: 3
      out_ch: 3
      ch: 128
      ch_mult:
        - 1
        - 2
        - 4
        - 4
      num_res_blocks: 2
      attn_resolutions: [ ]
      dropout: 0.0

text_enc_params1:
  model_path: M-CLIP/XLM-Roberta-Large-Vit-B-16Plus
  model_name: multiclip

text_enc_params2:
  model_path: google/mt5-small
  model_name: MT5EncoderModel


tokenizer_name1: M-CLIP/XLM-Roberta-Large-Vit-B-16Plus
tokenizer_name2: google/mt5-small